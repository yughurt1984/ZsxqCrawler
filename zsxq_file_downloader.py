#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çŸ¥è¯†æ˜Ÿçƒæ–‡ä»¶ä¸‹è½½å™¨
Author: AI Assistant
Date: 2024-12-19
Description: ä¸“é—¨ç”¨äºä¸‹è½½çŸ¥è¯†æ˜Ÿçƒæ–‡ä»¶çš„å·¥å…·
"""

import datetime
import json
import os
import random
import time
from typing import Dict, Optional, Any

import requests

from zsxq_file_database import ZSXQFileDatabase


class ZSXQFileDownloader:
    """çŸ¥è¯†æ˜Ÿçƒæ–‡ä»¶ä¸‹è½½å™¨"""
    
    def __init__(self, cookie: str, group_id: str, db_path: str = None, download_dir: str = "downloads",
                 download_interval: float = 1.0, long_sleep_interval: float = 60.0,
                 files_per_batch: int = 10, download_interval_min: float = None,
                 download_interval_max: float = None, long_sleep_interval_min: float = None,
                 long_sleep_interval_max: float = None, wecom_webhook=None, log_callback=None):
        """
        åˆå§‹åŒ–æ–‡ä»¶ä¸‹è½½å™¨

        Args:
            cookie: ç™»å½•å‡­è¯
            group_id: æ˜ŸçƒID
            db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœä¸ºNoneï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„ï¼‰
            download_dir: ä¸‹è½½ç›®å½•
            download_interval: å•æ¬¡ä¸‹è½½é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤1ç§’
            long_sleep_interval: é•¿ä¼‘çœ é—´éš”ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤60ç§’
            files_per_batch: ä¸‹è½½å¤šå°‘æ–‡ä»¶åè§¦å‘é•¿ä¼‘çœ ï¼Œé»˜è®¤10ä¸ªæ–‡ä»¶
            download_interval_min: éšæœºä¸‹è½½é—´éš”æœ€å°å€¼ï¼ˆç§’ï¼‰
            download_interval_max: éšæœºä¸‹è½½é—´éš”æœ€å¤§å€¼ï¼ˆç§’ï¼‰
            long_sleep_interval_min: éšæœºé•¿ä¼‘çœ é—´éš”æœ€å°å€¼ï¼ˆç§’ï¼‰
            long_sleep_interval_max: éšæœºé•¿ä¼‘çœ é—´éš”æœ€å¤§å€¼ï¼ˆç§’ï¼‰
        """
        self.cookie = self.clean_cookie(cookie)
        self.group_id = group_id

        # ä¸‹è½½é—´éš”æ§åˆ¶å‚æ•°
        self.download_interval = download_interval
        self.long_sleep_interval = long_sleep_interval
        self.files_per_batch = files_per_batch
        self.current_batch_count = 0  # å½“å‰æ‰¹æ¬¡å·²ä¸‹è½½æ–‡ä»¶æ•°

        # éšæœºé—´éš”èŒƒå›´å‚æ•°ï¼ˆå¦‚æœæä¾›äº†èŒƒå›´å‚æ•°ï¼Œåˆ™ä½¿ç”¨éšæœºé—´éš”ï¼‰
        self.use_random_interval = download_interval_min is not None
        if self.use_random_interval:
            self.download_interval_min = download_interval_min
            self.download_interval_max = download_interval_max
            self.long_sleep_interval_min = long_sleep_interval_min
            self.long_sleep_interval_max = long_sleep_interval_max
        else:
            # ä½¿ç”¨å›ºå®šé—´éš”æ—¶çš„é»˜è®¤èŒƒå›´å€¼ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
            self.download_interval_min = 60  # ä¸‹è½½é—´éš”æœ€å°å€¼ï¼ˆ1åˆ†é’Ÿï¼‰
            self.download_interval_max = 180  # ä¸‹è½½é—´éš”æœ€å¤§å€¼ï¼ˆ3åˆ†é’Ÿï¼‰
            self.long_sleep_interval_min = 180  # é•¿ä¼‘çœ æœ€å°å€¼ï¼ˆ3åˆ†é’Ÿï¼‰
            self.long_sleep_interval_max = 300  # é•¿ä¼‘çœ æœ€å¤§å€¼ï¼ˆ5åˆ†é’Ÿï¼‰

        # å¦‚æœæ²¡æœ‰æŒ‡å®šæ•°æ®åº“è·¯å¾„ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„
        if db_path is None:
            from db_path_manager import get_db_path_manager
            path_manager = get_db_path_manager()
            self.db_path = path_manager.get_files_db_path(group_id)
        else:
            self.db_path = db_path

        # ä¸ºæ¯ä¸ªç¾¤ç»„åˆ›å»ºä¸“å±çš„ä¸‹è½½ç›®å½•
        if download_dir == "downloads":  # é»˜è®¤ç›®å½•
            from db_path_manager import get_db_path_manager
            path_manager = get_db_path_manager()
            group_dir = path_manager.get_group_dir(group_id)
            self.download_dir = os.path.join(group_dir, "downloads")
        else:
            # å¦‚æœæŒ‡å®šäº†è‡ªå®šä¹‰ç›®å½•ï¼Œä¹Ÿåœ¨å…¶ä¸‹åˆ›å»ºç¾¤ç»„å­ç›®å½•
            self.download_dir = os.path.join(download_dir, f"group_{group_id}")

        print(f"ğŸ“ ç¾¤ç»„ {group_id} ä¸‹è½½ç›®å½•: {self.download_dir}")
        self.base_url = "https://api.zsxq.com"

        # æ—¥å¿—å›è°ƒå’Œåœæ­¢æ£€æŸ¥å‡½æ•°
        self.log_callback = None
        self.stop_check_func = None
        self.stop_flag = False  # æœ¬åœ°åœæ­¢æ ‡å¿—

        # åæ£€æµ‹è®¾ç½®
        self.min_delay = 2.0  # æœ€å°å»¶è¿Ÿï¼ˆç§’ï¼‰
        self.max_delay = 5.0  # æœ€å¤§å»¶è¿Ÿï¼ˆç§’ï¼‰
        self.long_delay_interval = 5  # æ¯Nä¸ªæ–‡ä»¶è¿›è¡Œé•¿ä¼‘çœ 

        # ç»Ÿè®¡
        self.request_count = 0
        self.download_count = 0
        self.debug_mode = False

        # åˆ›å»ºsession
        self.session = requests.Session()

        # ç¡®ä¿ä¸‹è½½ç›®å½•å­˜åœ¨
        os.makedirs(self.download_dir, exist_ok=True)
        self.log(f"ğŸ“ ä¸‹è½½ç›®å½•: {os.path.abspath(self.download_dir)}")

        # ä½¿ç”¨å®Œæ•´çš„æ–‡ä»¶æ•°æ®åº“
        self.file_db = ZSXQFileDatabase(self.db_path)
        self.log(f"ğŸ“Š å®Œæ•´æ–‡ä»¶æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ: {self.db_path}")
        
        # ğŸ†• æ·»åŠ webhookå’Œæ—¥å¿—å›è°ƒ
        self.wecom_webhook = wecom_webhook
        self.log_callback = log_callback

    def log(self, message: str):
        """ç»Ÿä¸€çš„æ—¥å¿—è¾“å‡ºæ–¹æ³•"""
        print(message)
        if self.log_callback:
            self.log_callback(message)
        else:
            print(message)

    def format_file_size(self, size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°ä¸ºäººç±»å¯è¯»æ ¼å¼
        
        Args:
            size_bytes: æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
            
        Returns:
            æ ¼å¼åŒ–åçš„æ–‡ä»¶å¤§å°å­—ç¬¦ä¸²ï¼Œä¾‹å¦‚ "1.00 MB"
        """
        for unit in ['B', 'KB', 'MB', 'GB']:
            if size_bytes < 1024.0:
                return f"{size_bytes:.2f} {unit}"
            size_bytes /= 1024.0
        return f"{size_bytes:.2f} TB"


    def set_stop_flag(self):
        """è®¾ç½®åœæ­¢æ ‡å¿—"""
        self.stop_flag = True
        self.log("ğŸ›‘ æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œä»»åŠ¡å°†åœ¨ä¸‹ä¸€ä¸ªæ£€æŸ¥ç‚¹åœæ­¢")

    def is_stopped(self):
        """æ£€æŸ¥æ˜¯å¦è¢«åœæ­¢ï¼ˆç»¼åˆæ£€æŸ¥æœ¬åœ°æ ‡å¿—å’Œå¤–éƒ¨å‡½æ•°ï¼‰"""
        # é¦–å…ˆæ£€æŸ¥æœ¬åœ°åœæ­¢æ ‡å¿—
        if self.stop_flag:
            return True
        # ç„¶åæ£€æŸ¥å¤–éƒ¨åœæ­¢æ£€æŸ¥å‡½æ•°
        if self.stop_check_func and self.stop_check_func():
            self.stop_flag = True  # åŒæ­¥æœ¬åœ°æ ‡å¿—
            return True
        return False

    def check_stop(self):
        """æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢ï¼ˆå…¼å®¹æ—§æ–¹æ³•åï¼‰"""
        return self.is_stopped()
    
    def clean_cookie(self, cookie: str) -> str:
        """æ¸…ç†Cookieå­—ç¬¦ä¸²ï¼Œå»é™¤ä¸åˆæ³•å­—ç¬¦
        
        Args:
            cookie (str): åŸå§‹Cookieå­—ç¬¦ä¸²
        
        Returns:
            str: æ¸…ç†åçš„Cookieå­—ç¬¦ä¸²
        """
        try:
            # å¦‚æœæ˜¯bytesç±»å‹ï¼Œå…ˆè§£ç 
            if isinstance(cookie, bytes):
                cookie = cookie.decode('utf-8')
            
            # å»é™¤å¤šä½™çš„ç©ºæ ¼å’Œæ¢è¡Œç¬¦
            cookie = cookie.strip()
            
            # å¦‚æœæœ‰å¤šè¡Œï¼Œåªå–ç¬¬ä¸€è¡Œ
            if '\n' in cookie:
                cookie = cookie.split('\n')[0]
            
            # å»é™¤æœ«å°¾çš„åæ–œæ 
            cookie = cookie.rstrip('\\')
            
            # å»é™¤å¯èƒ½çš„å‰ç¼€bå’Œå¼•å·
            if cookie.startswith("b'") and cookie.endswith("'"):
                cookie = cookie[2:-1]
            elif cookie.startswith('b"') and cookie.endswith('"'):
                cookie = cookie[2:-1]
            elif cookie.startswith("'") and cookie.endswith("'"):
                cookie = cookie[1:-1]
            elif cookie.startswith('"') and cookie.endswith('"'):
                cookie = cookie[1:-1]
            
            # å¤„ç†è½¬ä¹‰å­—ç¬¦
            cookie = cookie.replace('\\n', '')
            cookie = cookie.replace('\\"', '"')
            cookie = cookie.replace("\\'", "'")
            
            # ç¡®ä¿åˆ†å·åæœ‰ç©ºæ ¼
            cookie = '; '.join(part.strip() for part in cookie.split(';'))
            
            return cookie
        except Exception as e:
            print(f"Cookieæ¸…ç†å¤±è´¥: {e}")
            return cookie  # è¿”å›åŸå§‹å€¼
    
    def get_stealth_headers(self) -> Dict[str, str]:
        """è·å–åæ£€æµ‹è¯·æ±‚å¤´ï¼ˆæ¯æ¬¡è°ƒç”¨éšæœºåŒ–ï¼‰"""
        # æ›´ä¸°å¯Œçš„User-Agentæ± 
        user_agents = [
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:132.0) Gecko/20100101 Firefox/132.0",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:131.0) Gecko/20100101 Firefox/131.0",
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36 Edg/131.0.0.0",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
            "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15",
            "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
            "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:132.0) Gecko/20100101 Firefox/132.0"
        ]
        
        # éšæœºé€‰æ‹©User-Agent
        selected_ua = random.choice(user_agents)
        
        # æ ¹æ®User-Agentç”Ÿæˆå¯¹åº”çš„Sec-Ch-Ua
        if "Chrome" in selected_ua:
            if "131.0.0.0" in selected_ua:
                sec_ch_ua = '"Google Chrome";v="131", "Chromium";v="131", "Not_A Brand";v="24"'
            elif "130.0.0.0" in selected_ua:
                sec_ch_ua = '"Google Chrome";v="130", "Chromium";v="130", "Not?A_Brand";v="99"'
            elif "129.0.0.0" in selected_ua:
                sec_ch_ua = '"Google Chrome";v="129", "Not=A?Brand";v="8", "Chromium";v="129"'
            else:
                sec_ch_ua = '"Google Chrome";v="131", "Chromium";v="131", "Not_A Brand";v="24"'
        else:
            sec_ch_ua = '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"'
        
        # éšæœºåŒ–å…¶ä»–å¤´éƒ¨
        accept_languages = [
            'zh-CN,zh;q=0.9,en;q=0.8',
            'zh-CN,zh;q=0.9,en;q=0.8,zh-TW;q=0.7',
            'zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7',
            'zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2'
        ]
        
        platforms = ['"Windows"', '"macOS"', '"Linux"']
        
        # åŸºç¡€å¤´éƒ¨
        headers = {
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': random.choice(accept_languages),
            'Accept-Encoding': 'gzip, deflate, br',
            'Cache-Control': 'no-cache',
            'Connection': 'keep-alive',
            'Cookie': self.cookie,
            'Host': 'api.zsxq.com',
            'Origin': 'https://wx.zsxq.com',
            'Pragma': 'no-cache',
            'Referer': f'https://wx.zsxq.com/dweb2/index/group/{self.group_id}',
            'Sec-Ch-Ua': sec_ch_ua,
            'Sec-Ch-Ua-Mobile': '?0',
            'Sec-Ch-Ua-Platform': random.choice(platforms),
            'Sec-Fetch-Dest': 'empty',
            'Sec-Fetch-Mode': 'cors',
            'Sec-Fetch-Site': 'same-site',
            'User-Agent': selected_ua
        }
        
        # éšæœºæ·»åŠ å¯é€‰å¤´éƒ¨
        optional_headers = {
            'DNT': '1',
            'Sec-GPC': '1',
            'Upgrade-Insecure-Requests': '1',
            'X-Requested-With': 'XMLHttpRequest'
        }
        
        for key, value in optional_headers.items():
            if random.random() > 0.5:  # 50%æ¦‚ç‡æ·»åŠ 
                headers[key] = value
        
        # éšæœºè°ƒæ•´æ—¶é—´æˆ³ç›¸å…³å¤´éƒ¨
        if random.random() > 0.7:  # 30%æ¦‚ç‡æ·»åŠ 
            headers['X-Timestamp'] = str(int(time.time()) + random.randint(-30, 30))
        
        if random.random() > 0.6:  # 40%æ¦‚ç‡æ·»åŠ 
            headers['X-Request-Id'] = f"req-{random.randint(100000000000, 999999999999)}"
        
        return headers
    
    def smart_delay(self):
        """æ™ºèƒ½å»¶è¿Ÿ"""
        delay = random.uniform(self.min_delay, self.max_delay)
        if self.debug_mode:
            print(f"   â±ï¸ å»¶è¿Ÿ {delay:.1f}ç§’")
        time.sleep(delay)
    
    def download_delay(self):
        """ä¸‹è½½é—´éš”å»¶è¿Ÿ"""
        if self.use_random_interval:
            # ä½¿ç”¨APIä¼ å…¥çš„éšæœºé—´éš”èŒƒå›´
            delay = random.uniform(self.download_interval_min, self.download_interval_max)
            print(f"â³ ä¸‹è½½é—´éš”: {delay:.0f}ç§’ ({delay/60:.1f}åˆ†é’Ÿ) [éšæœºèŒƒå›´: {self.download_interval_min}-{self.download_interval_max}ç§’]")
        else:
            # ä½¿ç”¨å›ºå®šé—´éš”
            delay = self.download_interval
            print(f"â³ ä¸‹è½½é—´éš”: {delay:.1f}ç§’ [å›ºå®šé—´éš”]")

        start_time = datetime.datetime.now()
        end_time = start_time + datetime.timedelta(seconds=delay)

        print(f"   â° å¼€å§‹æ—¶é—´: {start_time.strftime('%H:%M:%S')}")
        print(f"   ğŸ• é¢„è®¡æ¢å¤: {end_time.strftime('%H:%M:%S')}")

        time.sleep(delay)

        actual_end_time = datetime.datetime.now()
        print(f"   ğŸ• å®é™…ç»“æŸ: {actual_end_time.strftime('%H:%M:%S')}")
    
    def check_long_delay(self):
        """æ£€æŸ¥æ˜¯å¦éœ€è¦é•¿ä¼‘çœ """
        if self.download_count > 0 and self.download_count % self.long_delay_interval == 0:
            if self.use_random_interval:
                # ä½¿ç”¨APIä¼ å…¥çš„éšæœºé•¿ä¼‘çœ é—´éš”èŒƒå›´
                delay = random.uniform(self.long_sleep_interval_min, self.long_sleep_interval_max)
                print(f"ğŸ›Œ é•¿ä¼‘çœ å¼€å§‹: {delay:.0f}ç§’ ({delay/60:.1f}åˆ†é’Ÿ) [éšæœºèŒƒå›´: {self.long_sleep_interval_min/60:.1f}-{self.long_sleep_interval_max/60:.1f}åˆ†é’Ÿ]")
            else:
                # ä½¿ç”¨å›ºå®šé•¿ä¼‘çœ é—´éš”
                delay = self.long_sleep_interval
                print(f"ğŸ›Œ é•¿ä¼‘çœ å¼€å§‹: {delay:.0f}ç§’ ({delay/60:.1f}åˆ†é’Ÿ) [å›ºå®šé—´éš”]")

            start_time = datetime.datetime.now()
            end_time = start_time + datetime.timedelta(seconds=delay)

            print(f"   å·²ä¸‹è½½ {self.download_count} ä¸ªæ–‡ä»¶ï¼Œè¿›å…¥é•¿ä¼‘çœ æ¨¡å¼...")
            print(f"   â° å¼€å§‹æ—¶é—´: {start_time.strftime('%H:%M:%S')}")
            print(f"   ğŸ• é¢„è®¡æ¢å¤: {end_time.strftime('%H:%M:%S')}")

            time.sleep(delay)

            actual_end_time = datetime.datetime.now()
            print(f"ğŸ˜´ é•¿ä¼‘çœ ç»“æŸï¼Œç»§ç»­ä¸‹è½½...")
            print(f"   ğŸ• å®é™…ç»“æŸ: {actual_end_time.strftime('%H:%M:%S')}")
    
    def fetch_file_list(self, count: int = 20, index: Optional[str] = None, sort: str = "by_download_count") -> Optional[Dict[str, Any]]:
        """è·å–æ–‡ä»¶åˆ—è¡¨ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰"""
        url = f"{self.base_url}/v2/groups/{self.group_id}/files"
        max_retries = 10
        
        params = {
            "count": str(count),
            "sort": sort
        }
        
        if index:
            params["index"] = index
        
        self.log(f"ğŸŒ è·å–æ–‡ä»¶åˆ—è¡¨")
        self.log(f"   ğŸ“Š å‚æ•°: count={count}, sort={sort}")
        if index:
            self.log(f"   ğŸ“‘ ç´¢å¼•: {index}")
        self.log(f"   ğŸŒ è¯·æ±‚URL: {url}")
        
        for attempt in range(max_retries):
            if attempt > 0:
                # é‡è¯•å»¶è¿Ÿï¼š15-30ç§’
                retry_delay = random.uniform(15, 30)
                print(f"   ğŸ”„ ç¬¬{attempt}æ¬¡é‡è¯•ï¼Œç­‰å¾…{retry_delay:.1f}ç§’...")
                time.sleep(retry_delay)
            
            # æ¯æ¬¡é‡è¯•éƒ½è·å–æ–°çš„è¯·æ±‚å¤´ï¼ˆåŒ…å«æ–°çš„User-Agentç­‰ï¼‰
            self.smart_delay()
            self.request_count += 1
            headers = self.get_stealth_headers()
            
            if attempt > 0:
                print(f"   ğŸ”„ é‡è¯•#{attempt}: ä½¿ç”¨æ–°çš„User-Agent: {headers.get('User-Agent', 'N/A')[:50]}...")
            
            try:
                response = self.session.get(url, headers=headers, params=params, timeout=30)
                
                print(f"   ğŸ“Š å“åº”çŠ¶æ€: {response.status_code}")
                
                if response.status_code == 200:
                    try:
                        data = response.json()
                        
                        # åªåœ¨ç¬¬ä¸€æ¬¡å°è¯•æˆ–æœ€åä¸€æ¬¡å¤±è´¥æ—¶æ˜¾ç¤ºå®Œæ•´å“åº”
                        if attempt == 0 or attempt == max_retries - 1 or data.get('succeeded'):
                            print(f"   ğŸ“‹ å“åº”å†…å®¹: {json.dumps(data, ensure_ascii=False, indent=2)}")
                        
                        if data.get('succeeded'):
                            files = data.get('resp_data', {}).get('files', [])
                            next_index = data.get('resp_data', {}).get('index')
                            if attempt > 0:
                                print(f"   âœ… é‡è¯•æˆåŠŸï¼ç¬¬{attempt}æ¬¡é‡è¯•è·å–åˆ°æ–‡ä»¶åˆ—è¡¨")
                            else:
                                print(f"   âœ… è·å–æˆåŠŸ: {len(files)}ä¸ªæ–‡ä»¶")
                            return data
                        else:
                            error_msg = data.get('message', data.get('error', 'æœªçŸ¥é”™è¯¯'))
                            error_code = data.get('code', 'N/A')
                            print(f"   âŒ APIè¿”å›å¤±è´¥: {error_msg} (ä»£ç : {error_code})")
                            
                            # æ£€æŸ¥æ˜¯å¦æ˜¯å¯é‡è¯•çš„é”™è¯¯
                            if error_code in [1059, 500, 502, 503, 504]:  # å†…éƒ¨é”™è¯¯ã€æœåŠ¡å™¨é”™è¯¯ç­‰
                                if attempt < max_retries - 1:
                                    print(f"   ğŸ”„ æ£€æµ‹åˆ°å¯é‡è¯•é”™è¯¯ï¼Œå‡†å¤‡é‡è¯•...")
                                    continue
                            else:
                                print(f"   ğŸš« éå¯é‡è¯•é”™è¯¯ï¼Œåœæ­¢é‡è¯•")
                                return None
                                
                    except json.JSONDecodeError as e:
                        print(f"   âŒ JSONè§£æå¤±è´¥: {e}")
                        print(f"   ğŸ“„ åŸå§‹å“åº”: {response.text[:500]}...")
                        if attempt < max_retries - 1:
                            print(f"   ğŸ”„ JSONè§£æå¤±è´¥ï¼Œå‡†å¤‡é‡è¯•...")
                            continue
                        
                elif response.status_code in [429, 500, 502, 503, 504]:  # é¢‘ç‡é™åˆ¶æˆ–æœåŠ¡å™¨é”™è¯¯
                    print(f"   âŒ HTTPé”™è¯¯: {response.status_code}")
                    print(f"   ğŸ“„ å“åº”å†…å®¹: {response.text[:200]}...")
                    if attempt < max_retries - 1:
                        print(f"   ğŸ”„ æœåŠ¡å™¨é”™è¯¯ï¼Œå‡†å¤‡é‡è¯•...")
                        continue
                else:
                    print(f"   âŒ HTTPé”™è¯¯: {response.status_code}")
                    print(f"   ğŸ“„ å“åº”å†…å®¹: {response.text[:200]}...")
                    print(f"   ğŸš« éå¯é‡è¯•HTTPé”™è¯¯ï¼Œåœæ­¢é‡è¯•")
                    return None
                    
            except Exception as e:
                print(f"   âŒ è¯·æ±‚å¼‚å¸¸: {e}")
                if attempt < max_retries - 1:
                    print(f"   ğŸ”„ è¯·æ±‚å¼‚å¸¸ï¼Œå‡†å¤‡é‡è¯•...")
                    continue
        
        print(f"   ğŸš« å·²é‡è¯•{max_retries}æ¬¡ï¼Œå…¨éƒ¨å¤±è´¥")
        return None
    
    def get_download_url(self, file_id: int) -> Optional[str]:
        """è·å–æ–‡ä»¶ä¸‹è½½é“¾æ¥ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
        
        æ³¨æ„ï¼šfile_id å‚æ•°åœ¨ä¸åŒåœºæ™¯ä¸‹å«ä¹‰ä¸åŒï¼š
        - è¾¹è·å–è¾¹ä¸‹è½½æ—¶ï¼šä¼ å…¥çš„æ˜¯çœŸå®çš„ file_id
        - ä»æ•°æ®åº“ä¸‹è½½æ—¶ï¼šä¼ å…¥çš„æ˜¯ topic_id
        """
        url = f"{self.base_url}/v2/files/{file_id}/download_url"
        max_retries = 10
        
        self.log(f"   ğŸ”— è·å–ä¸‹è½½é“¾æ¥: ID={file_id}")
        self.log(f"   ğŸŒ è¯·æ±‚URL: {url}")
        
        for attempt in range(max_retries):
            if attempt > 0:
                # é‡è¯•å»¶è¿Ÿï¼š15-30ç§’
                retry_delay = random.uniform(15, 30)
                print(f"   ğŸ”„ ç¬¬{attempt}æ¬¡é‡è¯•ï¼Œç­‰å¾…{retry_delay:.1f}ç§’...")
                time.sleep(retry_delay)
            
            # æ¯æ¬¡é‡è¯•éƒ½è·å–æ–°çš„è¯·æ±‚å¤´ï¼ˆåŒ…å«æ–°çš„User-Agentç­‰ï¼‰
            self.smart_delay()
            self.request_count += 1
            headers = self.get_stealth_headers()
            
            if attempt > 0:
                print(f"   ğŸ”„ é‡è¯•#{attempt}: ä½¿ç”¨æ–°çš„User-Agent: {headers.get('User-Agent', 'N/A')[:50]}...")
            
            try:
                response = self.session.get(url, headers=headers, timeout=30)
                
                print(f"   ğŸ“Š å“åº”çŠ¶æ€: {response.status_code}")
                
                if response.status_code == 200:
                    try:
                        data = response.json()
                        
                        # åªåœ¨ç¬¬ä¸€æ¬¡å°è¯•æˆ–æœ€åä¸€æ¬¡å¤±è´¥æ—¶æ˜¾ç¤ºå®Œæ•´å“åº”
                        if attempt == 0 or attempt == max_retries - 1 or data.get('succeeded'):
                            print(f"   ğŸ“‹ å“åº”å†…å®¹: {json.dumps(data, ensure_ascii=False, indent=2)}")
                        
                        if data.get('succeeded'):
                            download_url = data.get('resp_data', {}).get('download_url')
                            if download_url:
                                if attempt > 0:
                                    print(f"   âœ… é‡è¯•æˆåŠŸï¼ç¬¬{attempt}æ¬¡é‡è¯•è·å–åˆ°ä¸‹è½½é“¾æ¥")
                                else:
                                    print(f"   âœ… è·å–ä¸‹è½½é“¾æ¥æˆåŠŸ")
                                return download_url
                            else:
                                print(f"   âŒ å“åº”ä¸­æ— ä¸‹è½½é“¾æ¥å­—æ®µ")
                        else:
                            error_msg = data.get('message', data.get('error', 'æœªçŸ¥é”™è¯¯'))
                            error_code = data.get('code', 'N/A')
                            self.log(f"   âŒ APIè¿”å›å¤±è´¥: {error_msg} (ä»£ç : {error_code})")

                            # æ£€æŸ¥æ˜¯å¦æ˜¯1030æƒé™é”™è¯¯
                            if error_code == 1030:
                                self.log(f"   ğŸš« æƒé™ä¸è¶³é”™è¯¯(1030)ï¼šæ­¤æ–‡ä»¶åªèƒ½åœ¨æ‰‹æœºç«¯ä¸‹è½½ï¼Œä»»åŠ¡å°†è‡ªåŠ¨åœæ­¢")
                                # è®¾ç½®åœæ­¢æ ‡å¿—ï¼Œè®©æ•´ä¸ªä»»åŠ¡åœæ­¢
                                self.set_stop_flag()
                                return None

                            # æ£€æŸ¥æ˜¯å¦æ˜¯å¯é‡è¯•çš„é”™è¯¯
                            if error_code in [1059, 500, 502, 503, 504]:  # å†…éƒ¨é”™è¯¯ã€æœåŠ¡å™¨é”™è¯¯ç­‰
                                if attempt < max_retries - 1:
                                    self.log(f"   ğŸ”„ æ£€æµ‹åˆ°å¯é‡è¯•é”™è¯¯ï¼Œå‡†å¤‡é‡è¯•...")
                                    continue
                            else:
                                self.log(f"   ğŸš« éå¯é‡è¯•é”™è¯¯ï¼Œåœæ­¢é‡è¯•")
                                return None
                                
                    except json.JSONDecodeError as e:
                        print(f"   âŒ JSONè§£æå¤±è´¥: {e}")
                        print(f"   ğŸ“„ åŸå§‹å“åº”: {response.text[:500]}...")
                        if attempt < max_retries - 1:
                            print(f"   ğŸ”„ JSONè§£æå¤±è´¥ï¼Œå‡†å¤‡é‡è¯•...")
                            continue
                        
                elif response.status_code in [429, 500, 502, 503, 504]:  # é¢‘ç‡é™åˆ¶æˆ–æœåŠ¡å™¨é”™è¯¯
                    print(f"   âŒ HTTPé”™è¯¯: {response.status_code}")
                    print(f"   ğŸ“„ å“åº”å†…å®¹: {response.text[:200]}...")
                    if attempt < max_retries - 1:
                        print(f"   ğŸ”„ æœåŠ¡å™¨é”™è¯¯ï¼Œå‡†å¤‡é‡è¯•...")
                        continue
                else:
                    print(f"   âŒ HTTPé”™è¯¯: {response.status_code}")
                    print(f"   ğŸ“„ å“åº”å†…å®¹: {response.text[:200]}...")
                    print(f"   ğŸš« éå¯é‡è¯•HTTPé”™è¯¯ï¼Œåœæ­¢é‡è¯•")
                    return None
                    
            except Exception as e:
                print(f"   âŒ è¯·æ±‚å¼‚å¸¸: {e}")
                if attempt < max_retries - 1:
                    print(f"   ğŸ”„ è¯·æ±‚å¼‚å¸¸ï¼Œå‡†å¤‡é‡è¯•...")
                    continue
        
        print(f"   ğŸš« å·²é‡è¯•{max_retries}æ¬¡ï¼Œå…¨éƒ¨å¤±è´¥")
        return None
    
    def download_file(self, file_info: Dict[str, Any]) -> bool:
        """ä¸‹è½½å•ä¸ªæ–‡ä»¶"""
        file_data = file_info.get('file', {})
        file_id = file_data.get('id') or file_data.get('file_id')
        file_name = file_data.get('name', 'Unknown')
        file_size = file_data.get('size', 0)
        download_count = file_data.get('download_count', 0)
        
        self.log(f"ğŸ“¥ å‡†å¤‡ä¸‹è½½æ–‡ä»¶:")
        self.log(f"   ğŸ“„ åç§°: {file_name}")
        self.log(f"   ğŸ“Š å¤§å°: {file_size:,} bytes ({file_size/1024/1024:.2f} MB)")
        self.log(f"   ğŸ“ˆ ä¸‹è½½æ¬¡æ•°: {download_count}")

        # æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢
        if self.check_stop():
            self.log("ğŸ›‘ ä¸‹è½½ä»»åŠ¡è¢«åœæ­¢")
            return False
        
        # æ¸…ç†æ–‡ä»¶åï¼ˆç§»é™¤éæ³•å­—ç¬¦ï¼‰
        safe_filename = "".join(c for c in file_name if c.isalnum() or c in '._-ï¼ˆï¼‰()[]{}')
        if not safe_filename:
            safe_filename = f"file_{file_id}"
        
        file_path = os.path.join(self.download_dir, safe_filename)
        
        # ğŸš€ ä¼˜åŒ–ï¼šå…ˆæ£€æŸ¥æœ¬åœ°æ–‡ä»¶ï¼Œé¿å…æ— æ„ä¹‰çš„APIè¯·æ±‚
        if os.path.exists(file_path):
            existing_size = os.path.getsize(file_path)
            if existing_size == file_size:
                self.log(f"   âœ… æ–‡ä»¶å·²å­˜åœ¨ä¸”å¤§å°åŒ¹é…ï¼Œè·³è¿‡ä¸‹è½½")
                return "skipped"  # è¿”å›ç‰¹æ®Šå€¼è¡¨ç¤ºè·³è¿‡
            else:
                self.log(f"   âš ï¸ æ–‡ä»¶å·²å­˜åœ¨ä½†å¤§å°ä¸åŒ¹é…ï¼Œé‡æ–°ä¸‹è½½")
        
        # åªæœ‰åœ¨éœ€è¦ä¸‹è½½æ—¶æ‰è·å–ä¸‹è½½é“¾æ¥
        download_url = self.get_download_url(file_id)
        if not download_url:
            self.log(f"   âŒ æ— æ³•è·å–ä¸‹è½½é“¾æ¥")
            return False

        try:
            # ä¸‹è½½æ–‡ä»¶
            self.log(f"   ğŸš€ å¼€å§‹ä¸‹è½½...")
            response = self.session.get(download_url, timeout=300, stream=True)

            # å¦‚æœæ–‡ä»¶åæ˜¯é»˜è®¤çš„ï¼Œå°è¯•ä»å“åº”å¤´è·å–çœŸå®æ–‡ä»¶å
            if file_name.startswith('file_') and 'content-disposition' in response.headers:
                content_disposition = response.headers['content-disposition']
                if 'filename=' in content_disposition:
                    # æå–æ–‡ä»¶å
                    import re
                    filename_match = re.search(r'filename[*]?=([^;]+)', content_disposition)
                    if filename_match:
                        real_filename = filename_match.group(1).strip('"\'')
                        if real_filename:
                            file_name = real_filename
                            safe_filename = "".join(c for c in file_name if c.isalnum() or c in '._-ï¼ˆï¼‰()[]{}')
                            if not safe_filename:
                                safe_filename = f"file_{file_id}"
                            file_path = os.path.join(self.download_dir, safe_filename)
                            self.log(f"   ğŸ“ ä»å“åº”å¤´è·å–åˆ°çœŸå®æ–‡ä»¶å: {file_name}")
            
            if response.status_code == 200:
                total_size = int(response.headers.get('content-length', 0))
                downloaded_size = 0
                
                with open(file_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                            downloaded_size += len(chunk)
                            
                            # æ˜¾ç¤ºè¿›åº¦ï¼ˆæ¯10MBæ˜¾ç¤ºä¸€æ¬¡ï¼‰
                            if downloaded_size % (10 * 1024 * 1024) == 0 or downloaded_size == total_size:
                                if total_size > 0:
                                    progress = (downloaded_size / total_size) * 100
                                    self.log(f"   ğŸ“Š è¿›åº¦: {progress:.1f}% ({downloaded_size:,}/{total_size:,} bytes)")

                            # æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢
                            if self.check_stop():
                                self.log("ğŸ›‘ ä¸‹è½½è¿‡ç¨‹ä¸­è¢«åœæ­¢")
                                return False

                            if downloaded_size % (10 * 1024 * 1024) != 0 and downloaded_size != total_size:
                                if total_size == 0:
                                    self.log(f"   ğŸ“Š å·²ä¸‹è½½: {downloaded_size:,} bytes")
                
                # éªŒè¯æ–‡ä»¶å¤§å°
                final_size = os.path.getsize(file_path)
                if file_size > 0 and final_size != file_size:
                    self.log(f"   âš ï¸ æ–‡ä»¶å¤§å°ä¸åŒ¹é…: é¢„æœŸ{file_size:,}, å®é™…{final_size:,}")

                self.log(f"   âœ… ä¸‹è½½å®Œæˆ: {safe_filename}")
                self.log(f"   ğŸ’¾ ä¿å­˜è·¯å¾„: {file_path}")

                self.download_count += 1
                self.current_batch_count += 1

                # ä¸‹è½½é—´éš”æ§åˆ¶
                self._apply_download_intervals()
                return True
            else:
                self.log(f"   âŒ ä¸‹è½½å¤±è´¥: HTTP {response.status_code}")
                return False

        except Exception as e:
            self.log(f"   âŒ ä¸‹è½½å¼‚å¸¸: {e}")
            if os.path.exists(file_path):
                os.remove(file_path)
                self.log(f"   ğŸ—‘ï¸ åˆ é™¤ä¸å®Œæ•´æ–‡ä»¶")
            return False

    def _apply_download_intervals(self):
        """åº”ç”¨ä¸‹è½½é—´éš”æ§åˆ¶"""
        import time

        # æ£€æŸ¥æ˜¯å¦éœ€è¦é•¿ä¼‘çœ 
        if self.current_batch_count >= self.files_per_batch:
            self.log(f"â° å·²ä¸‹è½½ {self.current_batch_count} ä¸ªæ–‡ä»¶ï¼Œå¼€å§‹é•¿ä¼‘çœ  {self.long_sleep_interval} ç§’...")
            time.sleep(self.long_sleep_interval)
            self.current_batch_count = 0  # é‡ç½®æ‰¹æ¬¡è®¡æ•°
            self.log(f"ğŸ˜´ é•¿ä¼‘çœ ç»“æŸï¼Œç»§ç»­ä¸‹è½½")
        else:
            # æ™®é€šä¸‹è½½é—´éš”
            if self.download_interval > 0:
                self.log(f"â±ï¸ ä¸‹è½½é—´éš”ä¼‘çœ  {self.download_interval} ç§’...")
                time.sleep(self.download_interval)

    def download_files_batch(self, max_files: Optional[int] = None, start_index: Optional[str] = None) -> Dict[str, int]:
        """æ‰¹é‡ä¸‹è½½æ–‡ä»¶"""
        if max_files is None:
            self.log(f"ğŸ“¥ å¼€å§‹æ— é™ä¸‹è½½æ–‡ä»¶ (ç›´åˆ°æ²¡æœ‰æ›´å¤šæ–‡ä»¶)")
        else:
            self.log(f"ğŸ“¥ å¼€å§‹æ‰¹é‡ä¸‹è½½æ–‡ä»¶ (æœ€å¤š{max_files}ä¸ª)")

        # æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢
        if self.check_stop():
            self.log("ğŸ›‘ ä»»åŠ¡è¢«åœæ­¢")
            return {'total_files': 0, 'downloaded': 0, 'skipped': 0, 'failed': 0}

        stats = {'total_files': 0, 'downloaded': 0, 'skipped': 0, 'failed': 0}
        current_index = start_index
        downloaded_in_batch = 0
        
        while max_files is None or downloaded_in_batch < max_files:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢
            if self.check_stop():
                self.log("ğŸ›‘ æ‰¹é‡ä¸‹è½½ä»»åŠ¡è¢«åœæ­¢")
                break

            # è·å–æ–‡ä»¶åˆ—è¡¨
            data = self.fetch_file_list(count=20, index=current_index)
            if not data:
                self.log("âŒ è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥")
                break

            files = data.get('resp_data', {}).get('files', [])
            next_index = data.get('resp_data', {}).get('index')

            if not files:
                self.log("ğŸ“­ æ²¡æœ‰æ›´å¤šæ–‡ä»¶")
                break

            self.log(f"ğŸ“‹ å½“å‰æ‰¹æ¬¡: {len(files)} ä¸ªæ–‡ä»¶")
            
            for i, file_info in enumerate(files):
                # æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢
                if self.check_stop():
                    self.log("ğŸ›‘ æ–‡ä»¶ä¸‹è½½è¿‡ç¨‹ä¸­è¢«åœæ­¢")
                    break

                if max_files is not None and downloaded_in_batch >= max_files:
                    break

                file_data = file_info.get('file', {})
                file_name = file_data.get('name', 'Unknown')

                if max_files is None:
                    self.log(f"ã€ç¬¬{downloaded_in_batch + 1}ä¸ªæ–‡ä»¶ã€‘{file_name}")
                else:
                    self.log(f"ã€{downloaded_in_batch + 1}/{max_files}ã€‘{file_name}")

                # ä¸‹è½½æ–‡ä»¶
                result = self.download_file(file_info)

                if result == "skipped":
                    stats['skipped'] += 1
                    self.log(f"   âš ï¸ æ–‡ä»¶å·²è·³è¿‡ï¼Œç»§ç»­ä¸‹ä¸€ä¸ª")
                elif result:
                    stats['downloaded'] += 1
                    downloaded_in_batch += 1

                    # æ£€æŸ¥é•¿ä¼‘çœ 
                    self.check_long_delay()

                    # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªæ–‡ä»¶ï¼Œè¿›è¡Œä¸‹è½½é—´éš”
                    has_more_in_batch = (i + 1) < len(files)
                    not_reached_limit = max_files is None or downloaded_in_batch < max_files
                    if has_more_in_batch and not_reached_limit:
                        self.download_delay()
                else:
                    stats['failed'] += 1
                
                stats['total_files'] += 1
            
            # å‡†å¤‡ä¸‹ä¸€é¡µ
            should_continue = max_files is None or downloaded_in_batch < max_files
            if next_index and should_continue:
                current_index = next_index
                self.log(f"ğŸ“„ å‡†å¤‡è·å–ä¸‹ä¸€é¡µ: {next_index}")
                time.sleep(2)  # é¡µé¢é—´çŸ­æš‚å»¶è¿Ÿ
            else:
                break

        self.log(f"ğŸ‰ æ‰¹é‡ä¸‹è½½å®Œæˆ:")
        self.log(f"   ğŸ“Š æ€»æ–‡ä»¶æ•°: {stats['total_files']}")
        self.log(f"   âœ… ä¸‹è½½æˆåŠŸ: {stats['downloaded']}")
        self.log(f"   âš ï¸ è·³è¿‡: {stats['skipped']}")
        self.log(f"   âŒ å¤±è´¥: {stats['failed']}")
        
        return stats
    
    def show_file_list(self, count: int = 20, index: Optional[str] = None) -> Optional[str]:
        """æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨"""
        data = self.fetch_file_list(count=count, index=index)
        if not data:
            return None
        
        files = data.get('resp_data', {}).get('files', [])
        next_index = data.get('resp_data', {}).get('index')
        
        print(f"\nğŸ“‹ æ–‡ä»¶åˆ—è¡¨ ({len(files)} ä¸ªæ–‡ä»¶):")
        print("="*80)
        
        for i, file_info in enumerate(files, 1):
            file_data = file_info.get('file', {})
            topic_data = file_info.get('topic', {})
            
            file_name = file_data.get('name', 'Unknown')
            file_size = file_data.get('size', 0)
            download_count = file_data.get('download_count', 0)
            create_time = file_data.get('create_time', 'Unknown')
            
            topic_title = topic_data.get('talk', {}).get('text', '')[:50] if topic_data.get('talk') else ''
            
            print(f"{i:2d}. ğŸ“„ {file_name}")
            print(f"    ğŸ“Š å¤§å°: {file_size:,} bytes ({file_size/1024/1024:.2f} MB)")
            print(f"    ğŸ“ˆ ä¸‹è½½: {download_count} æ¬¡")
            print(f"    â° æ—¶é—´: {create_time}")
            if topic_title:
                print(f"    ğŸ’¬ è¯é¢˜: {topic_title}...")
            print()
        
        if next_index:
            print(f"ğŸ“‘ ä¸‹ä¸€é¡µç´¢å¼•: {next_index}")
        else:
            print("ğŸ“­ æ²¡æœ‰æ›´å¤šæ–‡ä»¶")
        
        return next_index
    
    def collect_all_files_to_database(self) -> Dict[str, int]:
        """æ”¶é›†æ‰€æœ‰æ–‡ä»¶ä¿¡æ¯åˆ°æ•°æ®åº“"""
        print(f"\nğŸ“Š å¼€å§‹æ”¶é›†æ–‡ä»¶åˆ—è¡¨åˆ°æ•°æ®åº“...")
        
        # åˆ›å»ºæ”¶é›†è®°å½•
        self.file_db.cursor.execute("INSERT INTO collection_log (start_time) VALUES (?)", 
                      (datetime.datetime.now().isoformat(),))
        log_id = self.file_db.cursor.lastrowid
        self.file_db.conn.commit()
        
        stats = {'total_files': 0, 'new_files': 0, 'skipped_files': 0}
        current_index = None
        page_count = 0
        
        try:
            while True:
                page_count += 1
                print(f"\nğŸ“„ æ”¶é›†ç¬¬{page_count}é¡µæ–‡ä»¶åˆ—è¡¨...")
                
                # è·å–æ–‡ä»¶åˆ—è¡¨
                data = self.fetch_file_list(count=20, index=current_index)
                if not data:
                    print(f"âŒ ç¬¬{page_count}é¡µè·å–å¤±è´¥ï¼Œæ”¶é›†è¿‡ç¨‹ä¸­æ–­")
                    print(f"ğŸ’¾ å·²æˆåŠŸæ”¶é›†å‰{page_count-1}é¡µçš„æ•°æ®")
                    break
                
                files = data.get('resp_data', {}).get('files', [])
                next_index = data.get('resp_data', {}).get('index')
                
                if not files:
                    print("ğŸ“­ æ²¡æœ‰æ›´å¤šæ–‡ä»¶")
                    break
                
                print(f"   ğŸ“‹ å½“å‰é¡µé¢: {len(files)} ä¸ªæ–‡ä»¶")
                
                # ä½¿ç”¨å®Œæ•´æ•°æ®åº“å¯¼å…¥æ•´ä¸ªAPIå“åº”
                try:
                    page_stats = self.file_db.import_file_response(data)
                    
                    stats['new_files'] += page_stats.get('files', 0)
                    stats['total_files'] += len(files)
                    
                    print(f"      âœ… æ–°å¢æ–‡ä»¶: {page_stats.get('files', 0)}")
                    print(f"      ğŸ“Š å…¶ä»–æ•°æ®: è¯é¢˜+{page_stats.get('topics', 0)}, ç”¨æˆ·+{page_stats.get('users', 0)}")
                    
                except Exception as e:
                    print(f"   âŒ ç¬¬{page_count}é¡µå­˜å‚¨å¤±è´¥: {e}")
                    continue
                
                print(f"   âœ… ç¬¬{page_count}é¡µå­˜å‚¨å®Œæˆ")
                
                # å‡†å¤‡ä¸‹ä¸€é¡µ
                if next_index:
                    current_index = next_index
                    # é¡µé¢é—´çŸ­æš‚å»¶è¿Ÿ
                    time.sleep(random.uniform(2, 5))
                else:
                    break
                    
        except KeyboardInterrupt:
            print(f"\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­æ”¶é›†")
        except Exception as e:
            print(f"\nâŒ æ”¶é›†è¿‡ç¨‹å¼‚å¸¸: {e}")
        
        # æ›´æ–°æ”¶é›†è®°å½•
        self.file_db.cursor.execute('''
            UPDATE collection_log SET 
                end_time = ?, total_files = ?, new_files = ?, status = 'completed'
            WHERE id = ?
        ''', (datetime.datetime.now().isoformat(), stats['total_files'], 
              stats['new_files'], log_id))
        self.file_db.conn.commit()
        
        print(f"\nğŸ‰ æ–‡ä»¶åˆ—è¡¨æ”¶é›†å®Œæˆ:")
        print(f"   ğŸ“Š å¤„ç†æ–‡ä»¶æ•°: {stats['total_files']}")
        print(f"   âœ… æ–°å¢æ–‡ä»¶: {stats['new_files']}")
        print(f"   âš ï¸ è·³è¿‡é‡å¤: {stats.get('skipped_files', 0)}")
        print(f"   ğŸ“„ æ”¶é›†é¡µæ•°: {page_count}")
        
        return stats
    
    def get_database_time_range(self) -> Dict[str, Any]:
        """è·å–å®Œæ•´æ•°æ®åº“ä¸­æ–‡ä»¶çš„æ—¶é—´èŒƒå›´ä¿¡æ¯"""
        # ä½¿ç”¨æ–°æ•°æ®åº“æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
        stats = self.file_db.get_database_stats()
        total_files = stats.get('files', 0)
        
        if total_files == 0:
            return {'has_data': False, 'total_files': 0}
        
        # è·å–æ—¶é—´èŒƒå›´
        self.file_db.cursor.execute('''
            SELECT MIN(create_time) as oldest_time, 
                   MAX(create_time) as newest_time,
                   COUNT(*) as total_count
            FROM files 
            WHERE create_time IS NOT NULL AND create_time != ''
        ''')
        
        result = self.file_db.cursor.fetchone()
        
        return {
            'has_data': True,
            'total_files': total_files,
            'oldest_time': result[0] if result else None,
            'newest_time': result[1] if result else None,
            'time_based_count': result[2] if result else 0
        }
    
    def collect_files_by_time(self, sort: str = "by_create_time", start_time: Optional[str] = None, **kwargs) -> Dict[str, int]:
        """æŒ‰æ—¶é—´é¡ºåºæ”¶é›†æ–‡ä»¶åˆ—è¡¨åˆ°æ•°æ®åº“ï¼ˆä½¿ç”¨å®Œæ•´çš„æ•°æ®åº“ç»“æ„ï¼‰"""
        self.log(f"ğŸ“Š å¼€å§‹æŒ‰æ—¶é—´é¡ºåºæ”¶é›†æ–‡ä»¶åˆ—è¡¨åˆ°å®Œæ•´æ•°æ®åº“...")
        self.log(f"   ğŸ“… æ’åºæ–¹å¼: {sort}")
        if start_time:
            self.log(f"   â° èµ·å§‹æ—¶é—´: {start_time}")
        
        # æ£€æŸ¥æ˜¯å¦å¼ºåˆ¶åˆ·æ–°
        force_refresh = kwargs.get('force_refresh', False)
        if force_refresh:
            self.log(f"   ğŸ”„ å¼ºåˆ¶åˆ·æ–°æ¨¡å¼: å°†æ”¶é›†æ‰€æœ‰æ–‡ä»¶ï¼ˆåŒ…æ‹¬å·²å­˜åœ¨çš„ï¼‰")
        elif sort == "by_create_time":
            self.log(f"   âœ… æ™ºèƒ½å»é‡æ¨¡å¼: é‡åˆ°å·²å­˜åœ¨çš„æ–‡ä»¶å°†åœæ­¢æ”¶é›†")

        # æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢
        if self.check_stop():
            self.log("ğŸ›‘ ä»»åŠ¡è¢«åœæ­¢")
            return {'total_files': 0, 'new_files': 0}

        # ä½¿ç”¨å®Œæ•´æ•°æ®åº“çš„ç»Ÿè®¡ä¿¡æ¯
        initial_stats = self.file_db.get_database_stats()
        initial_files = initial_stats.get('files', 0)
        self.log(f"   ğŸ“Š æ•°æ®åº“åˆå§‹çŠ¶æ€: {initial_files} ä¸ªæ–‡ä»¶")
        
        # å¦‚æœæ˜¯æŒ‰æ—¶é—´æ’åºä¸”éå¼ºåˆ¶åˆ·æ–°æ¨¡å¼ï¼Œè·å–æ•°æ®åº“ä¸­æœ€æ–°æ–‡ä»¶çš„æ—¶é—´æˆ³
        db_latest_time = None
        if sort == "by_create_time" and not force_refresh and initial_files > 0:
            self.file_db.cursor.execute('''
                SELECT MAX(create_time) FROM files 
                WHERE create_time IS NOT NULL AND create_time != ''
            ''')
            result = self.file_db.cursor.fetchone()
            if result and result[0]:
                db_latest_time = result[0]
                self.log(f"   ğŸ“… æ•°æ®åº“æœ€æ–°æ–‡ä»¶æ—¶é—´: {db_latest_time}")
        
        total_imported_stats = {
            'files': 0, 'topics': 0, 'users': 0, 'groups': 0,
            'images': 0, 'comments': 0, 'likes': 0, 'columns': 0, 'solutions': 0
        }
        current_index = start_time  # ä½¿ç”¨æ—¶é—´æˆ³ä½œä¸ºindex
        page_count = 0
        
        try:
            while True:
                # æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢
                if self.check_stop():
                    self.log("ğŸ›‘ æ–‡ä»¶æ”¶é›†ä»»åŠ¡è¢«åœæ­¢")
                    break

                page_count += 1
                self.log(f"ğŸ“„ æ”¶é›†ç¬¬{page_count}é¡µæ–‡ä»¶åˆ—è¡¨...")

                # è·å–æ–‡ä»¶åˆ—è¡¨ï¼ˆæŒ‰æ—¶é—´æ’åºï¼‰
                data = self.fetch_file_list(count=20, index=current_index, sort=sort)
                if not data:
                    self.log(f"âŒ ç¬¬{page_count}é¡µè·å–å¤±è´¥ï¼Œæ”¶é›†è¿‡ç¨‹ä¸­æ–­")
                    self.log(f"ğŸ’¾ å·²æˆåŠŸæ”¶é›†å‰{page_count-1}é¡µçš„æ•°æ®")
                    break
                
                files = data.get('resp_data', {}).get('files', [])
                next_index = data.get('resp_data', {}).get('index')
                
                if not files:
                    self.log("ğŸ“­ æ²¡æœ‰æ›´å¤šæ–‡ä»¶")
                    break

                self.log(f"   ğŸ“‹ å½“å‰é¡µé¢: {len(files)} ä¸ªæ–‡ä»¶")
                
                # å¦‚æœæ˜¯æŒ‰æ—¶é—´æ’åºä¸”éå¼ºåˆ¶åˆ·æ–°æ¨¡å¼ï¼Œæ£€æŸ¥æœ¬é¡µæ–‡ä»¶æ˜¯å¦æœ‰æ–°äºæ•°æ®åº“çš„
                should_stop_after_insert = False
                if sort == "by_create_time" and not force_refresh and db_latest_time:
                    # ç­›é€‰å‡ºæ–°äºæ•°æ®åº“çš„æ–‡ä»¶
                    newer_files = [
                        file_info for file_info in files
                        if file_info.get('file', {}).get('create_time', '') > db_latest_time
                    ]
                    
                    newer_count = len(newer_files)
                    older_count = len(files) - newer_count
                    
                    self.log(f"   ğŸ“Š æ—¶é—´åˆ†æ: æ–°äºæ•°æ®åº“{newer_count}ä¸ª, æ—§äºæˆ–ç­‰äºæ•°æ®åº“{older_count}ä¸ª")
                    
                    # å¦‚æœæ•´é¡µæ–‡ä»¶éƒ½ä¸æ–°äºæ•°æ®åº“æœ€æ–°æ—¶é—´ï¼Œè¯´æ˜åé¢çš„éƒ½æ˜¯æ—§æ•°æ®ï¼Œåœæ­¢æ”¶é›†
                    if newer_count == 0:
                        self.log(f"   âœ… æœ¬é¡µå…¨éƒ¨æ–‡ä»¶å‡å·²å­˜åœ¨äºæ•°æ®åº“ï¼ˆæ—¶é—´ä¸æ™šäºæ•°æ®åº“æœ€æ–°ï¼‰ï¼Œåœæ­¢æ”¶é›†")
                        self.log(f"   ğŸ’¡ æç¤º: å¦‚éœ€å¼ºåˆ¶é‡æ–°æ”¶é›†ï¼Œè¯·ä¼ å…¥ force_refresh=True å‚æ•°")
                        break
                    
                    # å¦‚æœæœ‰æ—§æ•°æ®ï¼Œåªä¿ç•™æ–°æ•°æ®ï¼Œå¹¶æ ‡è®°æ’å…¥ååœæ­¢
                    if older_count > 0:
                        self.log(f"   ğŸ”„ è¿‡æ»¤æ‰{older_count}ä¸ªæ—§æ•°æ®ï¼Œåªæ’å…¥{newer_count}ä¸ªæ–°æ•°æ®")
                        data['resp_data']['files'] = newer_files
                        should_stop_after_insert = True

                # ä½¿ç”¨å®Œæ•´æ•°æ®åº“å¯¼å…¥æ•´ä¸ªAPIå“åº”
                try:
                    page_stats = self.file_db.import_file_response(data)

                    # ç´¯è®¡ç»Ÿè®¡
                    for key in total_imported_stats:
                        total_imported_stats[key] += page_stats.get(key, 0)

                    self.log(f"   âœ… ç¬¬{page_count}é¡µå­˜å‚¨å®Œæˆ: æ–‡ä»¶+{page_stats.get('files', 0)}, è¯é¢˜+{page_stats.get('topics', 0)}")
                    
                    # å¦‚æœæœ¬é¡µæœ‰æ—§æ•°æ®ï¼Œæ’å…¥æ–°æ•°æ®ååœæ­¢
                    if should_stop_after_insert:
                        self.log(f"   âœ… å·²æ’å…¥æœ¬é¡µæ–°æ•°æ®ï¼Œåç»­é¡µé¢å‡ä¸ºæ—§æ•°æ®ï¼Œåœæ­¢æ”¶é›†")
                        self.log(f"   ğŸ’¡ æç¤º: å¦‚éœ€å¼ºåˆ¶é‡æ–°æ”¶é›†ï¼Œè¯·ä¼ å…¥ force_refresh=True å‚æ•°")
                        break

                except Exception as e:
                    self.log(f"   âŒ ç¬¬{page_count}é¡µå­˜å‚¨å¤±è´¥: {e}")
                    continue
                
                # å‡†å¤‡ä¸‹ä¸€é¡µ
                if next_index:
                    current_index = next_index
                    self.log(f"   â­ï¸ ä¸‹ä¸€é¡µæ—¶é—´æˆ³: {current_index}")
                    # é¡µé¢é—´çŸ­æš‚å»¶è¿Ÿ
                    time.sleep(random.uniform(2, 5))
                else:
                    self.log("ğŸ“­ å·²åˆ°è¾¾æœ€åä¸€é¡µ")
                    break

        except KeyboardInterrupt:
            self.log(f"â¹ï¸ ç”¨æˆ·ä¸­æ–­æ”¶é›†")
        except Exception as e:
            self.log(f"âŒ æ”¶é›†è¿‡ç¨‹å¼‚å¸¸: {e}")

        # æœ€ç»ˆç»Ÿè®¡
        final_stats = self.file_db.get_database_stats()
        final_files = final_stats.get('files', 0)
        new_files = final_files - initial_files

        self.log(f"ğŸ‰ å®Œæ•´æ–‡ä»¶åˆ—è¡¨æ”¶é›†å®Œæˆ:")
        self.log(f"   ğŸ“Š å¤„ç†é¡µæ•°: {page_count}")
        self.log(f"   ğŸ“ æ–°å¢æ–‡ä»¶: {new_files} (æ€»è®¡: {final_files})")
        self.log(f"   ğŸ“‹ ç´¯è®¡å¯¼å…¥ç»Ÿè®¡:")
        for key, value in total_imported_stats.items():
            if value > 0:
                self.log(f"      {key}: +{value}")
        
        print(f"\nğŸ“Š å½“å‰æ•°æ®åº“çŠ¶æ€:")
        for table, count in final_stats.items():
            if count > 0:
                print(f"   {table}: {count}")
        
        return {
            'total_files': final_files,
            'new_files': new_files,
            'pages': page_count,
            **total_imported_stats
        }
    
    def collect_incremental_files(self) -> Dict[str, int]:
        """å¢é‡æ”¶é›†ï¼šä»æ•°æ®åº“æœ€è€æ—¶é—´æˆ³å¼€å§‹ç»§ç»­æ”¶é›†"""
        self.log(f"ğŸ”„ å¼€å§‹å¢é‡æ–‡ä»¶æ”¶é›†...")

        # æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢
        if self.check_stop():
            self.log("ğŸ›‘ ä»»åŠ¡è¢«åœæ­¢")
            return {'total_files': 0, 'new_files': 0}

        # è·å–æ•°æ®åº“æ—¶é—´èŒƒå›´
        time_info = self.get_database_time_range()

        if not time_info['has_data']:
            self.log("ğŸ“Š æ•°æ®åº“ä¸ºç©ºï¼Œå°†è¿›è¡Œå…¨é‡æ”¶é›†")
            return self.collect_files_by_time()
        
        oldest_time = time_info['oldest_time']
        newest_time = time_info['newest_time']
        total_files = time_info['total_files']
        
        self.log(f"ğŸ“Š æ•°æ®åº“ç°çŠ¶:")
        self.log(f"   ç°æœ‰æ–‡ä»¶æ•°: {total_files}")
        self.log(f"   æœ€è€æ—¶é—´: {oldest_time}")
        self.log(f"   æœ€æ–°æ—¶é—´: {newest_time}")

        if not oldest_time:
            self.log("âš ï¸ æ•°æ®åº“ä¸­æ²¡æœ‰æœ‰æ•ˆçš„æ—¶é—´ä¿¡æ¯ï¼Œè¿›è¡Œå…¨é‡æ”¶é›†")
            return self.collect_files_by_time()

        # ä»æœ€è€æ—¶é—´æˆ³å¼€å§‹æ”¶é›†æ›´æ—©çš„æ–‡ä»¶
        self.log(f"ğŸ¯ å°†ä»æœ€è€æ—¶é—´æˆ³å¼€å§‹æ”¶é›†æ›´æ—©çš„æ–‡ä»¶...")
        
        # å°†æ—¶é—´æˆ³è½¬æ¢ä¸ºæ¯«ç§’æ•°ç”¨ä½œindex
        try:
            if '+' in oldest_time:
                # å¤„ç†å¸¦æ—¶åŒºçš„æ—¶é—´æˆ³
                from datetime import datetime
                dt = datetime.fromisoformat(oldest_time.replace('+0800', '+08:00'))
                timestamp_ms = int(dt.timestamp() * 1000)
            else:
                # å¦‚æœå·²ç»æ˜¯æ¯«ç§’æ—¶é—´æˆ³
                timestamp_ms = int(oldest_time)
            
            start_index = str(timestamp_ms)
            self.log(f"ğŸš€ å¢é‡æ”¶é›†èµ·å§‹æ—¶é—´æˆ³: {start_index}")

            return self.collect_files_by_time(start_time=start_index)

        except Exception as e:
            self.log(f"âš ï¸ æ—¶é—´æˆ³å¤„ç†å¤±è´¥: {e}")
            self.log("ğŸ”„ æ”¹ä¸ºå…¨é‡æ”¶é›†")
            return self.collect_files_by_time()
    
    def download_files_from_database(self, max_files: Optional[int] = None, status_filter: str = 'pending', **kwargs) -> Dict[str, int]:
        """ä»å®Œæ•´æ•°æ®åº“ä¸‹è½½æ–‡ä»¶ï¼ˆä½¿ç”¨file_idå­—æ®µï¼‰"""
        self.log(f"ğŸ“¥ å¼€å§‹ä»å®Œæ•´æ•°æ®åº“ä¸‹è½½æ–‡ä»¶...")
        if max_files:
            self.log(f"   ğŸ¯ ä¸‹è½½é™åˆ¶: {max_files}ä¸ªæ–‡ä»¶")
        self.log(f"   ğŸ” çŠ¶æ€ç­›é€‰: {status_filter}")
        recent_days = kwargs.get('recent_days')
        if recent_days:
            self.log(f"   ğŸ“… æ—¶é—´ç­›é€‰: æœ€è¿‘{recent_days}å¤©")
        order_by = kwargs.get('order_by', 'create_time DESC')
        self.log(f"   ğŸ”ƒ æ’åºæ–¹å¼: {order_by}")

        # æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢
        if self.check_stop():
            self.log("ğŸ›‘ ä»»åŠ¡è¢«åœæ­¢")
            return {'total_files': 0, 'downloaded': 0, 'skipped': 0, 'failed': 0}
        
        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        query_conditions = "download_status = ?"
        query_params = [status_filter]
        
        # å¦‚æœæŒ‡å®šäº†recent_daysï¼Œæ·»åŠ æ—¶é—´ç­›é€‰æ¡ä»¶
        if recent_days:
            from datetime import datetime, timedelta
            cutoff_date = (datetime.now() - timedelta(days=recent_days)).strftime('%Y-%m-%dT%H:%M:%S')
            query_conditions += " AND create_time >= ?"
            query_params.append(cutoff_date)
        
        # ä»å®Œæ•´æ•°æ®åº“è·å–æ–‡ä»¶åˆ—è¡¨ï¼ˆä½¿ç”¨çŠ¶æ€ç­›é€‰å’Œæ—¶é—´ç­›é€‰ï¼‰
        if max_files:
            query = f'''
                SELECT file_id, name, size, download_count, create_time 
                FROM files 
                WHERE {query_conditions}
                ORDER BY {order_by}
                LIMIT ?
            '''
            query_params.append(max_files)
            self.file_db.cursor.execute(query, tuple(query_params))
        else:
            query = f'''
                SELECT file_id, name, size, download_count, create_time 
                FROM files 
                WHERE {query_conditions}
                ORDER BY {order_by}
            '''
            self.file_db.cursor.execute(query, tuple(query_params))
        
        files_to_download = self.file_db.cursor.fetchall()
        
        if not files_to_download:
            self.log(f"ğŸ“­ æ•°æ®åº“ä¸­æ²¡æœ‰çŠ¶æ€ä¸º '{status_filter}' çš„æ–‡ä»¶å¯ä¸‹è½½")
            return {'total_files': 0, 'downloaded': 0, 'skipped': 0, 'failed': 0}

        self.log(f"ğŸ“‹ æ‰¾åˆ° {len(files_to_download)} ä¸ªå¾…ä¸‹è½½æ–‡ä»¶")

        stats = {'total_files': len(files_to_download), 'downloaded': 0, 'skipped': 0, 'failed': 0}

        for i, (file_id, file_name, file_size, download_count, create_time) in enumerate(files_to_download, 1):
            # æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢
            if self.check_stop():
                self.log("ğŸ›‘ ä¸‹è½½ä»»åŠ¡è¢«åœæ­¢")
                break

            try:
                self.log(f"ã€{i}/{len(files_to_download)}ã€‘{file_name}")
                self.log(f"   ğŸ“Š æ–‡ä»¶ID: {file_id}, å¤§å°: {file_size/1024:.1f}KB, ä¸‹è½½æ¬¡æ•°: {download_count}")
                
                # æ„é€ æ–‡ä»¶ä¿¡æ¯ç»“æ„ï¼ˆä½¿ç”¨æ­£ç¡®çš„file_idï¼‰
                file_info = {
                    'file': {
                        'id': file_id,  # ä½¿ç”¨æ­£ç¡®çš„file_id
                        'name': file_name,
                        'size': file_size,
                        'download_count': download_count
                    }
                }
                
                # ä¸‹è½½æ–‡ä»¶
                result = self.download_file(file_info)
                
                if result == "skipped":
                    stats['skipped'] += 1
                    self.log(f"   âš ï¸ æ–‡ä»¶å·²è·³è¿‡")
                    # æ›´æ–°æ•°æ®åº“çŠ¶æ€ä¸ºå·²è·³è¿‡
                    self.file_db.cursor.execute('''
                        UPDATE files 
                        SET download_status = 'skipped',
                            download_time = CURRENT_TIMESTAMP
                        WHERE file_id = ?
                    ''', (file_id,))
                    self.file_db.conn.commit()
                elif result:
                    stats['downloaded'] += 1
                    # æ›´æ–°æ•°æ®åº“çŠ¶æ€ä¸ºå·²å®Œæˆ
                    safe_filename = "".join(c for c in file_name if c.isalnum() or c in '._-ï¼ˆï¼‰()[]{}')
                    if not safe_filename:
                        safe_filename = f"file_{file_id}"
                    file_path = os.path.join(self.download_dir, safe_filename)
                    
                    self.file_db.cursor.execute('''
                        UPDATE files 
                        SET download_status = 'completed',
                            local_path = ?,
                            download_time = CURRENT_TIMESTAMP
                        WHERE file_id = ?
                    ''', (file_path, file_id))
                    self.file_db.conn.commit()
                    self.log(f"   âœ… æ•°æ®åº“çŠ¶æ€å·²æ›´æ–°ä¸º: completed")

                    # æ£€æŸ¥é•¿ä¼‘çœ 
                    self.check_long_delay()

                    # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªæ–‡ä»¶ï¼Œè¿›è¡Œä¸‹è½½é—´éš”
                    if i < len(files_to_download):
                        self.download_delay()
                else:
                    stats['failed'] += 1
                    self.log(f"   âŒ ä¸‹è½½å¤±è´¥")
                    # æ›´æ–°æ•°æ®åº“çŠ¶æ€ä¸ºå¤±è´¥
                    self.file_db.cursor.execute('''
                        UPDATE files 
                        SET download_status = 'failed',
                            download_time = CURRENT_TIMESTAMP
                        WHERE file_id = ?
                    ''', (file_id,))
                    self.file_db.conn.commit()
                
            except KeyboardInterrupt:
                self.log(f"â¹ï¸ ç”¨æˆ·ä¸­æ–­ä¸‹è½½")
                break
            except Exception as e:
                self.log(f"   âŒ å¤„ç†æ–‡ä»¶å¼‚å¸¸: {e}")
                stats['failed'] += 1
                continue

        self.log(f"ğŸ‰ æ•°æ®åº“ä¸‹è½½å®Œæˆ:")
        self.log(f"   ğŸ“Š æ€»æ–‡ä»¶æ•°: {stats['total_files']}")
        self.log(f"   âœ… ä¸‹è½½æˆåŠŸ: {stats['downloaded']}")
        self.log(f"   âš ï¸ è·³è¿‡: {stats['skipped']}")
        self.log(f"   âŒ å¤±è´¥: {stats['failed']}")
        
        return stats
    
    def show_database_stats(self):
        """æ˜¾ç¤ºå®Œæ•´æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        print(f"\nğŸ“Š å®Œæ•´æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯:")
        print("="*60)
        print(f"ğŸ“ æ•°æ®åº“æ–‡ä»¶: {self.db_path}")
        
        # ä½¿ç”¨æ–°æ•°æ®åº“çš„ç»Ÿè®¡æ–¹æ³•
        stats = self.file_db.get_database_stats()
        
        # ä¸»è¦æ•°æ®ç»Ÿè®¡
        total_files = stats.get('files', 0)
        total_topics = stats.get('topics', 0)
        total_users = stats.get('users', 0)
        total_groups = stats.get('groups', 0)
        
        print(f"ğŸ“ˆ æ ¸å¿ƒæ•°æ®:")
        print(f"   ğŸ“„ æ–‡ä»¶æ•°é‡: {total_files:,}")
        print(f"   ğŸ’¬ è¯é¢˜æ•°é‡: {total_topics:,}")
        print(f"   ğŸ‘¥ ç”¨æˆ·æ•°é‡: {total_users:,}")
        print(f"   ğŸ  ç¾¤ç»„æ•°é‡: {total_groups:,}")
        
        # æ–‡ä»¶å¤§å°ç»Ÿè®¡
        self.file_db.cursor.execute("SELECT SUM(size) FROM files WHERE size IS NOT NULL")
        result = self.file_db.cursor.fetchone()
        total_size = result[0] if result and result[0] else 0
        
        if total_size > 0:
            print(f"ğŸ’¾ æ€»æ–‡ä»¶å¤§å°: {total_size/1024/1024:.2f} MB")
        
        # è¯¦ç»†è¡¨ç»Ÿè®¡
        print(f"\nğŸ“‹ è¯¦ç»†è¡¨ç»Ÿè®¡:")
        for table_name, count in stats.items():
            if count > 0:
                # æ·»åŠ è¡¨æƒ…ç¬¦å·
                emoji_map = {
                    'files': 'ğŸ“„', 'groups': 'ğŸ ', 'users': 'ğŸ‘¥', 'topics': 'ğŸ’¬',
                    'talks': 'ğŸ’­', 'images': 'ğŸ–¼ï¸', 'topic_files': 'ğŸ“',
                    'latest_likes': 'ğŸ‘', 'comments': 'ğŸ’¬', 'like_emojis': 'ğŸ˜Š',
                    'user_liked_emojis': 'â¤ï¸', 'columns': 'ğŸ“š', 'topic_columns': 'ğŸ”—',
                    'solutions': 'ğŸ’¡', 'solution_files': 'ğŸ“‹', 'file_topic_relations': 'ğŸ”—',
                    'api_responses': 'ğŸ“¡'
                }
                emoji = emoji_map.get(table_name, 'ğŸ“Š')
                print(f"   {emoji} {table_name}: {count:,}")
        
        # æ–‡ä»¶åˆ›å»ºæ—¶é—´èŒƒå›´
        self.file_db.cursor.execute('''
            SELECT MIN(create_time), MAX(create_time), COUNT(*) 
            FROM files 
            WHERE create_time IS NOT NULL
        ''')
        time_result = self.file_db.cursor.fetchone()
        
        if time_result and time_result[2] > 0:
            min_time, max_time, time_count = time_result
            print(f"\nâ° æ–‡ä»¶æ—¶é—´èŒƒå›´:")
            print(f"   æœ€æ—©æ–‡ä»¶: {min_time}")
            print(f"   æœ€æ–°æ–‡ä»¶: {max_time}")
            print(f"   æœ‰æ—¶é—´ä¿¡æ¯çš„æ–‡ä»¶: {time_count:,}")
        
        # APIå“åº”ç»Ÿè®¡
        self.file_db.cursor.execute('''
            SELECT succeeded, COUNT(*) 
            FROM api_responses 
            GROUP BY succeeded
        ''')
        api_stats = self.file_db.cursor.fetchall()
        
        if api_stats:
            print(f"\nğŸ“¡ APIå“åº”ç»Ÿè®¡:")
            for succeeded, count in api_stats:
                status = "æˆåŠŸ" if succeeded else "å¤±è´¥"
                emoji = "âœ…" if succeeded else "âŒ"
                print(f"   {emoji} {status}: {count:,}")
        
        print("="*60)
    
    def adjust_settings(self):
        """è°ƒæ•´ä¸‹è½½è®¾ç½®"""
        print(f"\nğŸ”§ å½“å‰ä¸‹è½½è®¾ç½®:")
        print(f"   ä¸‹è½½é—´éš”: {self.download_interval_min}-{self.download_interval_max}ç§’ ({self.download_interval_min/60:.1f}-{self.download_interval_max/60:.1f}åˆ†é’Ÿ)")
        print(f"   é•¿ä¼‘çœ é—´éš”: æ¯{self.long_delay_interval}ä¸ªæ–‡ä»¶")
        print(f"   é•¿ä¼‘çœ æ—¶é—´: {self.long_delay_min}-{self.long_delay_max}ç§’ ({self.long_delay_min/60:.1f}-{self.long_delay_max/60:.1f}åˆ†é’Ÿ)")
        print(f"   ä¸‹è½½ç›®å½•: {self.download_dir}")
        
        try:
            new_interval = int(input(f"é•¿ä¼‘çœ é—´éš” (å½“å‰æ¯{self.long_delay_interval}ä¸ªæ–‡ä»¶): ") or self.long_delay_interval)
            new_dir = input(f"ä¸‹è½½ç›®å½• (å½“å‰: {self.download_dir}): ").strip() or self.download_dir
            
            self.long_delay_interval = max(new_interval, 1)
            
            if new_dir != self.download_dir:
                self.download_dir = new_dir
                os.makedirs(new_dir, exist_ok=True)
                print(f"ğŸ“ ä¸‹è½½ç›®å½•å·²æ›´æ–°: {os.path.abspath(new_dir)}")
            
            print(f"âœ… è®¾ç½®å·²æ›´æ–°")
            
        except ValueError:
            print("âŒ è¾“å…¥æ— æ•ˆï¼Œä¿æŒåŸè®¾ç½®")
    
    def close(self):
        """å…³é—­èµ„æº"""
        if hasattr(self, 'file_db') and self.file_db:
            self.file_db.close()
            print("ğŸ”’ æ–‡ä»¶æ•°æ®åº“è¿æ¥å·²å…³é—­") 